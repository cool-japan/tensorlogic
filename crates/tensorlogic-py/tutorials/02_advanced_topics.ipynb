{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorLogic Python Tutorial: Advanced Topics\n",
    "\n",
    "This notebook covers advanced features of TensorLogic for experienced users.\n",
    "\n",
    "## Topics Covered\n",
    "\n",
    "1. Multi-arity predicates and relational reasoning\n",
    "2. Nested quantifiers and complex queries\n",
    "3. Performance optimization and graph inspection\n",
    "4. Strategy selection for different use cases\n",
    "5. Integration patterns\n",
    "6. Error handling and debugging\n",
    "7. Best practices and tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytensorlogic as tl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "print(f\"TensorLogic version: {tl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multi-Arity Predicates\n",
    "\n",
    "### 1.1 Binary Predicates\n",
    "\n",
    "Binary predicates represent relations between two entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define binary predicate: knows(x, y)\n",
    "x = tl.var(\"x\")\n",
    "y = tl.var(\"y\")\n",
    "knows = tl.pred(\"knows\", [x, y])\n",
    "\n",
    "# Compile and execute\n",
    "graph = tl.compile(knows)\n",
    "\n",
    "# Knowledge graph: 3x3 matrix (who knows whom)\n",
    "# 1.0 = definitely knows, 0.0 = doesn't know, 0.5 = might know\n",
    "knows_data = np.array([\n",
    "    [0.0, 1.0, 0.5],  # Person 0 knows person 1, might know person 2\n",
    "    [1.0, 0.0, 1.0],  # Person 1 knows persons 0 and 2\n",
    "    [0.5, 1.0, 0.0],  # Person 2 knows person 1, might know person 0\n",
    "])\n",
    "\n",
    "result = tl.execute(graph, {\"knows\": knows_data})\n",
    "\n",
    "print(\"Knows relation matrix:\")\n",
    "print(knows_data)\n",
    "print(f\"\\nGraph execution result shape: {result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Ternary Predicates\n",
    "\n",
    "Ternary predicates involve three entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ternary predicate: gave(giver, item, receiver)\n",
    "giver = tl.var(\"giver\")\n",
    "item = tl.var(\"item\")\n",
    "receiver = tl.var(\"receiver\")\n",
    "gave = tl.pred(\"gave\", [giver, item, receiver])\n",
    "\n",
    "# Compile\n",
    "graph = tl.compile(gave)\n",
    "\n",
    "# 3D tensor: 2 people × 3 items × 2 people\n",
    "# gave[i,j,k] = probability that person i gave item j to person k\n",
    "gave_data = np.random.rand(2, 3, 2)\n",
    "\n",
    "result = tl.execute(graph, {\"gave\": gave_data})\n",
    "\n",
    "print(f\"Gave relation tensor shape: {gave_data.shape}\")\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "print(f\"\\nExample: Person 0 gave item 1 to person 1 with probability {gave_data[0,1,1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Complex Query: Transitive Closure\n",
    "\n",
    "Query: If A knows B and B knows C, does A indirectly know C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "a = tl.var(\"a\")\n",
    "b = tl.var(\"b\")\n",
    "c = tl.var(\"c\")\n",
    "\n",
    "# Predicates\n",
    "knows_ab = tl.pred(\"knows_ab\", [a, b])\n",
    "knows_bc = tl.pred(\"knows_bc\", [b, c])\n",
    "\n",
    "# Query: EXISTS b. (knows(a,b) AND knows(b,c))\n",
    "query = tl.exists(\"b\", \"Person\", tl.and_expr(knows_ab, knows_bc))\n",
    "\n",
    "# Compile\n",
    "graph = tl.compile(query)\n",
    "\n",
    "# Knowledge matrix (3 people)\n",
    "knows_matrix = np.array([\n",
    "    [0.0, 0.9, 0.0],  # Person 0 knows person 1\n",
    "    [0.0, 0.0, 0.8],  # Person 1 knows person 2\n",
    "    [0.0, 0.0, 0.0],  # Person 2 knows nobody\n",
    "])\n",
    "\n",
    "# Execute: for each (a,c) pair, check if there's an intermediate b\n",
    "result = tl.execute(graph, {\"knows_ab\": knows_matrix, \"knows_bc\": knows_matrix})\n",
    "\n",
    "print(\"Direct knowledge:\")\n",
    "print(knows_matrix)\n",
    "print(f\"\\nIndirect knowledge (via one intermediary):\")\n",
    "print(result.reshape(3, 3))\n",
    "print(f\"\\nPerson 0 indirectly knows person 2 with probability {result.reshape(3,3)[0,2]:.3f}\")\n",
    "print(f\"(via person 1: 0.9 * 0.8 = {0.9 * 0.8:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Nested Quantifiers\n",
    "\n",
    "### 2.1 Double Quantification\n",
    "\n",
    "Query: FORALL x. EXISTS y. knows(x, y)\n",
    "\n",
    "\"Everyone knows at least one person\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "x = tl.var(\"x\")\n",
    "y = tl.var(\"y\")\n",
    "\n",
    "# Predicate\n",
    "knows = tl.pred(\"knows\", [x, y])\n",
    "\n",
    "# EXISTS y. knows(x, y) - \"x knows at least one person\"\n",
    "exists_knows = tl.exists(\"y\", \"Person\", knows)\n",
    "\n",
    "# FORALL x. EXISTS y. knows(x, y) - \"everyone knows at least one person\"\n",
    "forall_exists = tl.forall(\"x\", \"Person\", exists_knows)\n",
    "\n",
    "# Compile\n",
    "graph = tl.compile(forall_exists)\n",
    "\n",
    "# Test scenarios\n",
    "scenarios = [\n",
    "    (\"Everyone connected\", np.array([\n",
    "        [0.0, 0.9, 0.8],\n",
    "        [0.9, 0.0, 0.7],\n",
    "        [0.8, 0.7, 0.0],\n",
    "    ])),\n",
    "    (\"One isolated\", np.array([\n",
    "        [0.0, 0.9, 0.0],\n",
    "        [0.9, 0.0, 0.8],\n",
    "        [0.0, 0.0, 0.0],  # Person 2 is isolated\n",
    "    ])),\n",
    "]\n",
    "\n",
    "for name, knows_data in scenarios:\n",
    "    result = tl.execute(graph, {\"knows\": knows_data})\n",
    "    print(f\"{name}:\")\n",
    "    print(knows_data)\n",
    "    print(f\"FORALL x. EXISTS y. knows(x,y): {result[0]:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Triple Quantification\n",
    "\n",
    "Query: FORALL x. EXISTS y. FORALL z. (knows(x,y) -> knows(y,z))\n",
    "\n",
    "\"Everyone has at least one friend who knows everyone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is complex! Let's build it step by step\n",
    "\n",
    "x = tl.var(\"x\")\n",
    "y = tl.var(\"y\")\n",
    "z = tl.var(\"z\")\n",
    "\n",
    "knows_xy = tl.pred(\"knows_xy\", [x, y])\n",
    "knows_yz = tl.pred(\"knows_yz\", [y, z])\n",
    "\n",
    "# knows(x,y) -> knows(y,z)\n",
    "implication = tl.imply(knows_xy, knows_yz)\n",
    "\n",
    "# FORALL z. (knows(x,y) -> knows(y,z))\n",
    "forall_z = tl.forall(\"z\", \"Person\", implication)\n",
    "\n",
    "# EXISTS y. FORALL z. (knows(x,y) -> knows(y,z))\n",
    "exists_y = tl.exists(\"y\", \"Person\", forall_z)\n",
    "\n",
    "# FORALL x. EXISTS y. FORALL z. (knows(x,y) -> knows(y,z))\n",
    "query = tl.forall(\"x\", \"Person\", exists_y)\n",
    "\n",
    "# Compile\n",
    "graph = tl.compile(query)\n",
    "\n",
    "# Knowledge matrix with one \"super-connector\" (person 1)\n",
    "knows_data = np.array([\n",
    "    [0.0, 0.9, 0.5],  # Person 0 knows person 1\n",
    "    [0.9, 0.0, 0.9],  # Person 1 knows everyone\n",
    "    [0.5, 0.9, 0.0],  # Person 2 knows person 1\n",
    "])\n",
    "\n",
    "result = tl.execute(graph, {\"knows_xy\": knows_data, \"knows_yz\": knows_data})\n",
    "\n",
    "print(\"Knowledge matrix:\")\n",
    "print(knows_data)\n",
    "print(f\"\\nQuery result: {result[0]:.3f}\")\n",
    "print(\"Interpretation: Does everyone have a super-connector friend?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Optimization\n",
    "\n",
    "### 3.1 Graph Inspection\n",
    "\n",
    "Understand the compiled graph structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a complex expression\n",
    "x = tl.var(\"x\")\n",
    "y = tl.var(\"y\")\n",
    "p = tl.pred(\"P\", [x])\n",
    "q = tl.pred(\"Q\", [y])\n",
    "r = tl.pred(\"R\", [x, y])\n",
    "\n",
    "# Complex query: (P(x) AND Q(y)) OR R(x,y)\n",
    "and_pq = tl.and_expr(p, q)\n",
    "expr = tl.or_expr(and_pq, r)\n",
    "\n",
    "# Compile\n",
    "graph = tl.compile(expr)\n",
    "\n",
    "# Inspect graph statistics\n",
    "stats = graph.stats()\n",
    "\n",
    "print(\"Graph Statistics:\")\n",
    "print(\"=\"*40)\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key:20} : {value}\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- tensors: Number of tensor operands\")\n",
    "print(\"- operations: Number of operations in the graph\")\n",
    "print(\"- total_nodes: Total computation nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Benchmarking Strategies\n",
    "\n",
    "Compare compilation and execution time across strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_strategy(strategy_name: str, config: tl.CompilationConfig, \n",
    "                      expr: tl.TLExpr, inputs: Dict[str, np.ndarray], \n",
    "                      n_trials: int = 100) -> Tuple[float, float]:\n",
    "    \"\"\"Benchmark compilation and execution time.\"\"\"\n",
    "    \n",
    "    # Benchmark compilation\n",
    "    compile_times = []\n",
    "    for _ in range(n_trials):\n",
    "        start = time.perf_counter()\n",
    "        graph = tl.compile_with_config(expr, config)\n",
    "        compile_times.append(time.perf_counter() - start)\n",
    "    \n",
    "    # Benchmark execution\n",
    "    graph = tl.compile_with_config(expr, config)\n",
    "    exec_times = []\n",
    "    for _ in range(n_trials):\n",
    "        start = time.perf_counter()\n",
    "        result = tl.execute(graph, inputs)\n",
    "        exec_times.append(time.perf_counter() - start)\n",
    "    \n",
    "    return np.mean(compile_times), np.mean(exec_times)\n",
    "\n",
    "# Create test expression\n",
    "x = tl.var(\"x\")\n",
    "p = tl.pred(\"P\", [x])\n",
    "q = tl.pred(\"Q\", [x])\n",
    "r = tl.pred(\"R\", [x])\n",
    "expr = tl.and_expr(tl.or_expr(p, q), tl.not_expr(r))\n",
    "\n",
    "# Test data (100 elements)\n",
    "inputs = {\n",
    "    \"P\": np.random.rand(100),\n",
    "    \"Q\": np.random.rand(100),\n",
    "    \"R\": np.random.rand(100),\n",
    "}\n",
    "\n",
    "# Benchmark strategies\n",
    "strategies = [\n",
    "    (\"Soft Differentiable\", tl.CompilationConfig()),\n",
    "    (\"Hard Boolean\", tl.CompilationConfig()),\n",
    "    (\"Fuzzy Gödel\", tl.CompilationConfig()),\n",
    "]\n",
    "\n",
    "results = {}\n",
    "print(\"Benchmarking strategies (100 trials each):\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Strategy':<20} {'Compile (μs)':<15} {'Execute (μs)':<15}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for name, config in strategies:\n",
    "    compile_time, exec_time = benchmark_strategy(name, config, expr, inputs, n_trials=100)\n",
    "    results[name] = (compile_time, exec_time)\n",
    "    print(f\"{name:<20} {compile_time*1e6:<15.2f} {exec_time*1e6:<15.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Visualize Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data\n",
    "strategy_names = list(results.keys())\n",
    "compile_times = [results[s][0] * 1e6 for s in strategy_names]  # Convert to μs\n",
    "exec_times = [results[s][1] * 1e6 for s in strategy_names]\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Compilation time\n",
    "ax1.bar(strategy_names, compile_times, color='blue', alpha=0.7)\n",
    "ax1.set_ylabel('Time (μs)', fontsize=12)\n",
    "ax1.set_title('Compilation Time', fontsize=14)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Execution time\n",
    "ax2.bar(strategy_names, exec_times, color='green', alpha=0.7)\n",
    "ax2.set_ylabel('Time (μs)', fontsize=12)\n",
    "ax2.set_title('Execution Time', fontsize=14)\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Strategy Selection Guide\n",
    "\n",
    "### When to Use Each Strategy\n",
    "\n",
    "| Strategy | Use Case | Pros | Cons |\n",
    "|----------|----------|------|------|\n",
    "| **soft_differentiable** | Neural-symbolic AI, training | Smooth gradients, differentiable | May not satisfy crisp logic laws |\n",
    "| **hard_boolean** | Classical logic, verification | Exact boolean semantics | Not differentiable, binary only |\n",
    "| **fuzzy_godel** | Fuzzy logic, multi-valued reasoning | Satisfies many logical laws | Different semantics than classical |\n",
    "| **fuzzy_product** | Probabilistic reasoning (independence) | Intuitive product semantics | Different from classical logic |\n",
    "| **fuzzy_lukasiewicz** | Resource-aware reasoning | Bounded sum/difference | Complex semantics |\n",
    "| **probabilistic** | Probability theory | Probabilistic interpretation | May violate logical laws |\n",
    "\n",
    "### Strategy Selection Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Training neural-symbolic model -> soft_differentiable\n",
    "print(\"Use Case 1: Training Neural-Symbolic Model\")\n",
    "print(\"Recommendation: soft_differentiable\")\n",
    "print(\"Reason: Smooth gradients enable backpropagation\\n\")\n",
    "\n",
    "# Example 2: Verifying safety properties -> hard_boolean\n",
    "print(\"Use Case 2: Verifying Safety Properties\")\n",
    "print(\"Recommendation: hard_boolean\")\n",
    "print(\"Reason: Exact boolean semantics ensure correctness\\n\")\n",
    "\n",
    "# Example 3: Multi-valued expert system -> fuzzy_godel\n",
    "print(\"Use Case 3: Multi-Valued Expert System\")\n",
    "print(\"Recommendation: fuzzy_godel\")\n",
    "print(\"Reason: Natural interpretation for degrees of truth\\n\")\n",
    "\n",
    "# Example 4: Probabilistic knowledge graph -> probabilistic\n",
    "print(\"Use Case 4: Probabilistic Knowledge Graph\")\n",
    "print(\"Recommendation: probabilistic\")\n",
    "print(\"Reason: Direct probabilistic interpretation\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Integration Patterns\n",
    "\n",
    "### 5.1 Iterative Reasoning\n",
    "\n",
    "Apply rules iteratively until convergence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_reasoning(graph: tl.EinsumGraph, \n",
    "                       initial_state: Dict[str, np.ndarray],\n",
    "                       max_iterations: int = 10,\n",
    "                       tolerance: float = 1e-6) -> np.ndarray:\n",
    "    \"\"\"Apply a rule iteratively until convergence.\"\"\"\n",
    "    \n",
    "    state = initial_state.copy()\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # Execute rule\n",
    "        new_state = tl.execute(graph, state)\n",
    "        \n",
    "        # Check convergence\n",
    "        if np.allclose(new_state, list(state.values())[0], atol=tolerance):\n",
    "            print(f\"Converged after {iteration+1} iterations\")\n",
    "            return new_state\n",
    "        \n",
    "        # Update state\n",
    "        state = {list(state.keys())[0]: new_state}\n",
    "    \n",
    "    print(f\"Did not converge after {max_iterations} iterations\")\n",
    "    return new_state\n",
    "\n",
    "# Example: Happiness propagation\n",
    "# Rule: If you have happy friends, you become happier\n",
    "x = tl.var(\"x\")\n",
    "y = tl.var(\"y\")\n",
    "happy = tl.pred(\"happy\", [y])\n",
    "friends = tl.pred(\"friends\", [x, y])\n",
    "has_happy_friend = tl.exists(\"y\", \"Person\", tl.and_expr(happy, friends))\n",
    "\n",
    "graph = tl.compile(has_happy_friend)\n",
    "\n",
    "# Initial state: one person is happy\n",
    "initial_happy = np.array([1.0, 0.0, 0.0, 0.0])\n",
    "friends_matrix = np.array([\n",
    "    [0.0, 0.8, 0.0, 0.0],\n",
    "    [0.8, 0.0, 0.9, 0.0],\n",
    "    [0.0, 0.9, 0.0, 0.7],\n",
    "    [0.0, 0.0, 0.7, 0.0],\n",
    "])\n",
    "\n",
    "# Run iterative reasoning\n",
    "final_state = iterative_reasoning(\n",
    "    graph, \n",
    "    {\"happy\": initial_happy, \"friends\": friends_matrix},\n",
    "    max_iterations=10\n",
    ")\n",
    "\n",
    "print(f\"\\nInitial happiness: {initial_happy}\")\n",
    "print(f\"Final happiness:   {final_state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Combining Multiple Rules\n",
    "\n",
    "Apply multiple rules in sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rules(rules: List[Tuple[str, tl.EinsumGraph]],\n",
    "               initial_state: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Apply multiple rules in sequence.\"\"\"\n",
    "    \n",
    "    state = initial_state.copy()\n",
    "    \n",
    "    for rule_name, graph in rules:\n",
    "        result = tl.execute(graph, state)\n",
    "        print(f\"Applied rule '{rule_name}': {result}\")\n",
    "        # Update state with new derived facts\n",
    "        state[rule_name + \"_result\"] = result\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Example: Multi-step reasoning\n",
    "x = tl.var(\"x\")\n",
    "p = tl.pred(\"P\", [x])\n",
    "q = tl.pred(\"Q\", [x])\n",
    "\n",
    "# Rule 1: P(x) AND Q(x) -> R(x)\n",
    "rule1 = tl.and_expr(p, q)\n",
    "graph1 = tl.compile(rule1)\n",
    "\n",
    "# Rule 2: NOT R(x) -> S(x)\n",
    "r = tl.pred(\"R\", [x])\n",
    "rule2 = tl.not_expr(r)\n",
    "graph2 = tl.compile(rule2)\n",
    "\n",
    "# Initial state\n",
    "initial_state = {\n",
    "    \"P\": np.array([1.0, 0.8, 0.5, 0.0]),\n",
    "    \"Q\": np.array([1.0, 0.6, 0.0, 0.0]),\n",
    "}\n",
    "\n",
    "# Apply rules\n",
    "rules = [(\"R_derivation\", graph1), (\"S_derivation\", graph2)]\n",
    "final_state = apply_rules(rules, initial_state)\n",
    "\n",
    "print(\"\\nFinal state:\")\n",
    "for key, value in final_state.items():\n",
    "    print(f\"{key:20} : {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Error Handling and Debugging\n",
    "\n",
    "### 6.1 Common Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error 1: Mismatched tensor shapes\n",
    "try:\n",
    "    x = tl.var(\"x\")\n",
    "    p = tl.pred(\"P\", [x])\n",
    "    graph = tl.compile(p)\n",
    "    \n",
    "    # Wrong: P expects 1D array, given 2D\n",
    "    result = tl.execute(graph, {\"P\": np.array([[1.0, 2.0]])})\n",
    "except Exception as e:\n",
    "    print(f\"Error 1 - Shape mismatch: {type(e).__name__}\")\n",
    "    print(f\"Message: {str(e)}\\n\")\n",
    "\n",
    "# Error 2: Missing input\n",
    "try:\n",
    "    x = tl.var(\"x\")\n",
    "    p = tl.pred(\"P\", [x])\n",
    "    q = tl.pred(\"Q\", [x])\n",
    "    expr = tl.and_expr(p, q)\n",
    "    graph = tl.compile(expr)\n",
    "    \n",
    "    # Wrong: Q is missing\n",
    "    result = tl.execute(graph, {\"P\": np.array([1.0, 2.0])})\n",
    "except Exception as e:\n",
    "    print(f\"Error 2 - Missing input: {type(e).__name__}\")\n",
    "    print(f\"Message: {str(e)}\\n\")\n",
    "\n",
    "# Error 3: Invalid variable name\n",
    "try:\n",
    "    # Wrong: Empty variable name\n",
    "    x = tl.var(\"\")\n",
    "except Exception as e:\n",
    "    print(f\"Error 3 - Invalid variable: {type(e).__name__}\")\n",
    "    print(f\"Message: {str(e)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Debugging Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_expression(expr: tl.TLExpr, inputs: Dict[str, np.ndarray]) -> None:\n",
    "    \"\"\"Debug helper for expressions.\"\"\"\n",
    "    \n",
    "    print(\"Debug Information:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1. Compile\n",
    "    try:\n",
    "        graph = tl.compile(expr)\n",
    "        print(\"✓ Compilation successful\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Compilation failed: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 2. Inspect graph\n",
    "    stats = graph.stats()\n",
    "    print(f\"\\nGraph statistics:\")\n",
    "    for key, value in stats.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # 3. Check inputs\n",
    "    print(f\"\\nProvided inputs:\")\n",
    "    for key, value in inputs.items():\n",
    "        print(f\"  {key}: shape={value.shape}, dtype={value.dtype}\")\n",
    "    \n",
    "    # 4. Execute\n",
    "    try:\n",
    "        result = tl.execute(graph, inputs)\n",
    "        print(f\"\\n✓ Execution successful\")\n",
    "        print(f\"  Result shape: {result.shape}\")\n",
    "        print(f\"  Result dtype: {result.dtype}\")\n",
    "        print(f\"  Result range: [{np.min(result):.3f}, {np.max(result):.3f}]\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Execution failed: {e}\")\n",
    "\n",
    "# Example usage\n",
    "x = tl.var(\"x\")\n",
    "p = tl.pred(\"P\", [x])\n",
    "q = tl.pred(\"Q\", [x])\n",
    "expr = tl.and_expr(p, q)\n",
    "\n",
    "inputs = {\n",
    "    \"P\": np.array([0.8, 0.6, 0.4]),\n",
    "    \"Q\": np.array([0.9, 0.5, 0.1]),\n",
    "}\n",
    "\n",
    "debug_expression(expr, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Best Practices and Tips\n",
    "\n",
    "### 7.1 Expression Design\n",
    "\n",
    "**DO:**\n",
    "- Build expressions incrementally and test at each step\n",
    "- Use meaningful variable and predicate names\n",
    "- Check graph statistics for complex expressions\n",
    "- Normalize input data to [0, 1] range for fuzzy/soft strategies\n",
    "\n",
    "**DON'T:**\n",
    "- Create deeply nested expressions without testing\n",
    "- Mix different semantic interpretations (e.g., probabilities and truth values)\n",
    "- Ignore compilation strategy implications\n",
    "- Use hard_boolean with continuous values\n",
    "\n",
    "### 7.2 Performance Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tip 1: Reuse compiled graphs\n",
    "x = tl.var(\"x\")\n",
    "p = tl.pred(\"P\", [x])\n",
    "q = tl.pred(\"Q\", [x])\n",
    "expr = tl.and_expr(p, q)\n",
    "\n",
    "# GOOD: Compile once, execute many times\n",
    "graph = tl.compile(expr)\n",
    "for i in range(100):\n",
    "    inputs = {\n",
    "        \"P\": np.random.rand(10),\n",
    "        \"Q\": np.random.rand(10),\n",
    "    }\n",
    "    result = tl.execute(graph, inputs)\n",
    "\n",
    "print(\"✓ Reused compiled graph 100 times\")\n",
    "\n",
    "# Tip 2: Batch processing\n",
    "# Instead of processing individual elements, batch them\n",
    "batch_size = 100\n",
    "p_batch = np.random.rand(batch_size)\n",
    "q_batch = np.random.rand(batch_size)\n",
    "result = tl.execute(graph, {\"P\": p_batch, \"Q\": q_batch})\n",
    "\n",
    "print(f\"✓ Processed batch of {batch_size} elements efficiently\")\n",
    "\n",
    "# Tip 3: Choose strategy based on requirements\n",
    "print(\"\\n✓ Strategy selection guide:\")\n",
    "print(\"  - Training? Use soft_differentiable\")\n",
    "print(\"  - Verification? Use hard_boolean\")\n",
    "print(\"  - Fuzzy logic? Use fuzzy_godel or fuzzy_product\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Type Safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using type hints for better code clarity\n",
    "from typing import Dict\n",
    "import numpy.typing as npt\n",
    "\n",
    "def safe_execute(graph: tl.EinsumGraph, \n",
    "                inputs: Dict[str, npt.NDArray[np.float64]]) -> npt.NDArray[np.float64]:\n",
    "    \"\"\"Type-safe execution wrapper.\"\"\"\n",
    "    \n",
    "    # Validate inputs\n",
    "    for key, value in inputs.items():\n",
    "        if not isinstance(value, np.ndarray):\n",
    "            raise TypeError(f\"Input '{key}' must be numpy array, got {type(value)}\")\n",
    "        if value.dtype != np.float64:\n",
    "            # Convert to float64\n",
    "            inputs[key] = value.astype(np.float64)\n",
    "    \n",
    "    # Execute\n",
    "    return tl.execute(graph, inputs)\n",
    "\n",
    "# Example usage\n",
    "x = tl.var(\"x\")\n",
    "p = tl.pred(\"P\", [x])\n",
    "graph = tl.compile(p)\n",
    "\n",
    "# This will work\n",
    "result = safe_execute(graph, {\"P\": np.array([1.0, 2.0, 3.0])})\n",
    "print(f\"✓ Safe execution successful: {result}\")\n",
    "\n",
    "# This will auto-convert to float64\n",
    "result = safe_execute(graph, {\"P\": np.array([1, 2, 3], dtype=np.int32)})\n",
    "print(f\"✓ Auto-converted int32 to float64: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "✅ **Multi-arity predicates** enable complex relational reasoning  \n",
    "✅ **Nested quantifiers** allow sophisticated queries  \n",
    "✅ **Graph inspection** helps understand compilation results  \n",
    "✅ **Benchmarking** informs strategy selection  \n",
    "✅ **Integration patterns** enable iterative and multi-rule reasoning  \n",
    "✅ **Error handling** improves robustness  \n",
    "✅ **Best practices** ensure efficient and correct usage  \n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Explore real-world datasets and knowledge graphs\n",
    "2. Integrate with neural network training pipelines\n",
    "3. Experiment with custom compilation strategies\n",
    "4. Build domain-specific reasoning systems\n",
    "5. Contribute to the TensorLogic ecosystem\n",
    "\n",
    "### Resources\n",
    "\n",
    "- **Documentation**: README.md, CLAUDE.md\n",
    "- **Tests**: `tests/` directory for usage examples\n",
    "- **Examples**: `examples/` directory\n",
    "- **Community**: GitHub issues and discussions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
